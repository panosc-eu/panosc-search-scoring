{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scoring based on the Search API\n",
    "\n",
    "The aim of this notebook to give an example how to populate the PaNOSC Search Scoring with the items to be scored from the reference implementation of the PaNOSC Search API.\n",
    "\n",
    "Requirements\n",
    "- A running instance of the reference implementation Search API service with enabled scoring.\n",
    "  (please use this branch: <https://github.com/panosc-eu/search-api/tree/SWAP-2417>)\n",
    "- A running instance of the PaNOSC Search Scoring service.\n",
    "\n",
    "\n",
    "**Important**: This example deletes all items from the given scoring API service and re-populates it based on the give search API service.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load required packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# load packages\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load configuration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# load configuration\n",
    "def load_configuration():\n",
    "    search_api_url = os.environ.get('SEARCH_API_URL', 'http://localhost:3000/api' )  # Address of the search API\n",
    "    score_api_url = os.environ.get('SCORE_API_URL', 'http://localhost:8000' )  # Address of the scoring API\n",
    "\n",
    "    dataset_filter = {\n",
    "        'filter': json.dumps({\n",
    "            'include': ['instrument', 'techniques', 'samples', 'parameters']\n",
    "        })\n",
    "    }\n",
    "\n",
    "    document_filter = {\n",
    "        'filter': json.dumps({\n",
    "            'include': [\n",
    "                    {\n",
    "                        'relation': 'members',\n",
    "                        'scope': {\n",
    "                            'include': ['person', 'affiliation']\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'relation': 'parameters',\n",
    "                    },\n",
    "                ]\n",
    "        })\n",
    "    }\n",
    "\n",
    "    dataset_mapper = {\n",
    "        'title': lambda d: d['title'],\n",
    "        'instrument': lambda d: copy_dict(d.get('instrument', {}), skip_fields=['pid']),\n",
    "        'techniques': lambda d: [copy_dict(t, skip_fields=['pid']) for t in d.get('techniques', [])],\n",
    "        'samples': lambda d: [copy_dict(t, skip_fields=['pid']) for t in d.get('samples', [])],\n",
    "        'parameters': lambda d: [copy_dict(t, skip_fields=['id', 'datasetId']) for t in d.get('parameters', [])],\n",
    "    }\n",
    "\n",
    "    document_mapper = {\n",
    "        'title': lambda d: d.get('title', ''),\n",
    "        'summary': lambda d: d.get('summary', ''),\n",
    "        'type': lambda d: d.get('type', ''),\n",
    "        'parameters': lambda d: [copy_dict(t, skip_fields=['id', 'documentId']) for t in d.get('parameters', [])],\n",
    "        'members': lambda d: [\n",
    "            {\n",
    "                'role': m.get('role', ''),\n",
    "                'person': copy_dict(m.get('person', {}), skip_fields=['id']),\n",
    "                'affiliation': copy_dict(m.get('affiliation', {}), skip_fields=['id']),\n",
    "            } for m in d.get('members', [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # TODO: It would be nice to have a loopback filter to skip mapping part, we need a loopback expert.\n",
    "\n",
    "    return {\n",
    "        'search_api_url': search_api_url,\n",
    "        'score_api_url': score_api_url,\n",
    "        'dataset_filter': dataset_filter,\n",
    "        'document_filter': document_filter,\n",
    "        'mappers': {\n",
    "            'datasets': dataset_mapper,\n",
    "            'documents': document_mapper,\n",
    "        },\n",
    "    }\n",
    "\n",
    "configuration = load_configuration()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect datasets via Search API (instrument, techniques, samples and parameters are included)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# get datasets\n",
    "def load_datasets(config):\n",
    "    response = requests.get(\n",
    "        url=f'{config[\"search_api_url\"]}/Datasets',\n",
    "        headers={'Accept': 'application/json'},\n",
    "        params=config['dataset_filter']\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "datasets = load_datasets(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect documents via Search API (members and parameters are included)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# get documents\n",
    "def load_documents(config):\n",
    "    response = requests.get(\n",
    "        url=f'{config[\"search_api_url\"]}/Documents',\n",
    "        headers={'Accept': 'application/json'},\n",
    "        params=config['document_filter']\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "documents = load_documents(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create data for scoring based on datasets and documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Create score data for datasets and documents\n",
    "def copy_dict(d, skip_fields=None):\n",
    "    skip = skip_fields if skip_fields is not None else []\n",
    "    return {k: v for k, v in d.items() if k not in skip}\n",
    "\n",
    "def extract(data, d_map, group):\n",
    "    fields = {key: mapper(data) for key, mapper in d_map.items()}\n",
    "    return {\n",
    "        'id': data['pid'],\n",
    "        'group': group,\n",
    "        'fields': fields,\n",
    "    }\n",
    "\n",
    "prepared_datasets = [extract(dataset, configuration['mappers']['datasets'], 'Datasets') for dataset in datasets]\n",
    "prepared_documents = [extract(document, configuration['mappers']['documents'], 'Documents') for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clear score database"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# Clear score database\n",
    "def clear_scoring_service(config):\n",
    "    count = requests.get(f'{config[\"score_api_url\"]}/items/count').json()['count']\n",
    "    if count > 0:\n",
    "        response = requests.get(\n",
    "            url=f'{config[\"score_api_url\"]}/items',\n",
    "            params={\n",
    "                'limit': count\n",
    "            }\n",
    "        )\n",
    "        current_items = response.json()\n",
    "        deleted_items = []\n",
    "        for item in current_items:\n",
    "            response = requests.delete(url='/'.join([f'{config[\"score_api_url\"]}/items', item['id']]))\n",
    "        deleted_items.append(response.status_code)\n",
    "\n",
    "clear_scoring_service(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Upload data to scoring service"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "# upload\n",
    "def upload_data(config, data):\n",
    "    requests.post(\n",
    "        url=f'{config[\"score_api_url\"]}/items',\n",
    "        json=data\n",
    "    )\n",
    "\n",
    "upload_data(config=configuration, data=prepared_datasets)\n",
    "upload_data(config=configuration, data=prepared_documents)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute weight information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# compute weight\n",
    "def compute_weight(config):\n",
    "    requests.post(\n",
    "        url=f'{config[\"score_api_url\"]}/compute'\n",
    "    )\n",
    "    # Wait till compute finishes\n",
    "    while requests.get(url=f'{config[\"score_api_url\"]}/compute').json()['inProgress']:\n",
    "        time.sleep(1)\n",
    "\n",
    "compute_weight(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test scoring"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itemId': '10.5072/panosc-document2', 'score': 0.45000000000000007, 'group': ''}\n",
      "{'itemId': '10.5072/panosc-document2', 'score': 0.45000000000000007, 'group': ''}\n"
     ]
    }
   ],
   "source": [
    "def check_only_scoring(config):\n",
    "    response = requests.post(\n",
    "        url=f'{config[\"score_api_url\"]}/score',\n",
    "        data=json.dumps(\n",
    "            {\n",
    "                'query': 'proposal',\n",
    "                'itemIds': [\n",
    "                    '10.5072/panosc-document1',\n",
    "                    '10.5072/panosc-document2',\n",
    "                ],\n",
    "                # 'group': 'Documents'\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        for item in response.json()['scores']:\n",
    "            print(f'{item}')\n",
    "    else:\n",
    "        print(f'{response.text}')\n",
    "\n",
    "check_only_scoring(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pid': '20.500.12269/panosc-dataset1', 'title': 'PaNOSC Test Dataset 1', 'isPublic': True, 'creationDate': '2020-05-05T15:01:02.341Z', 'instrumentId': '20.500.12269/0f98fcf2-7bd7-430e-ad20-d47031ca8f71'}, {'pid': '20.500.12269/panosc-dataset2', 'title': 'PaNOSC Test Dataset 2', 'isPublic': True, 'creationDate': '2020-05-05T15:01:02.341Z', 'instrumentId': '20.500.12269/125e8172-d0f4-4547-98be-a9db903a6269'}, {'pid': '20.500.12269/panosc-dataset3', 'title': 'PaNOSC Test Dataset 3', 'isPublic': True, 'creationDate': '2020-05-05T15:01:02.341Z', 'instrumentId': '20.500.12269/f0637030-9f89-4398-8f01-09211145efa1'}, {'pid': '20.500.12269/panosc-dataset4', 'title': 'PaNOSC Test Dataset 4', 'isPublic': True, 'creationDate': '2020-05-05T15:01:02.341Z', 'instrumentId': '20.500.12269/d3dd2880-637a-40b5-9815-990453817f0e'}]\n"
     ]
    }
   ],
   "source": [
    "def test_query(config=configuration):\n",
    "    response = requests.get(\n",
    "        url=f'{config[\"search_api_url\"]}/Datasets',\n",
    "        headers={'Accept': 'application/json'},\n",
    "        params={\n",
    "            'filter': json.dumps(\n",
    "                {\n",
    "                    \"query\": \"james pub\",\n",
    "                    \"limit\":50\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    print(response.json())\n",
    "test_query(config=configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}